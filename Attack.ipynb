{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Of42Ktq5Qr6"
      },
      "outputs": [],
      "source": [
        "!pip install kmedoids\n",
        "!pip install gdown\n",
        "!pip install python-mnist\n",
        "!pip install pulp\n",
        "!pip install scikit-learn==0.22.2 --upgrade\n",
        "!pip install zoopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwHtZKwz5q20"
      },
      "outputs": [],
      "source": [
        "%cd Fair-Clustering-Codebase/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mts-RZ9kTT6w"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfGHMVvV51A9"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "import pandas as pd\n",
        "import random\n",
        "import kmedoids\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.random_projection import SparseRandomProjection\n",
        "from zoopt import Dimension, ValueType, Objective, Parameter, Opt, ExpOpt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from fair_clustering.eval.functions import * #[TO-DO] Write base class and derive metrics from it, temporary eval code\n",
        "\n",
        "from fair_clustering.dataset import ExtendedYaleB, Office31, MNISTUSPS\n",
        "from fair_clustering.algorithm import FairSpectral, FairKCenter, FairletDecomposition, ScalableFairletDecomposition\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xgp3-g3RYGf7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMbLij2c7-Wl"
      },
      "outputs": [],
      "source": [
        "# Set parameters related to dataset and get dataset\n",
        "\n",
        "name = 'Office-31' #Choose between Office-31, MNIST_USPS, Yale, or DIGITS\n",
        "\n",
        "if name == 'Office-31':\n",
        "  dataset = Office31(exclude_domain='amazon', use_feature=True)\n",
        "  X, y, s = dataset.data\n",
        "elif name == 'MNIST_USPS':\n",
        "  dataset = MNISTUSPS(download=True)\n",
        "  X, y, s = dataset.data\n",
        "elif name == 'Yale':\n",
        "  dataset = ExtendedYaleB(download=True, resize=True)\n",
        "  X, y, s = dataset.data\n",
        "elif name == 'DIGITS':\n",
        "  X, y, s = np.load('X_' + name + '.npy'), np.load('y_' + name + '.npy'), np.load('s_' + name + '.npy')\n",
        "\n",
        "print(X.shape, y.shape, s.shape)\n",
        "\n",
        "cl_algo = 'SFD' #Choose between FSC or SFD. For KFC run notebook locally (KFC is not available in Colab due to CPLEX being incompatible with Colab)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aXpU_Zq7sFm"
      },
      "outputs": [],
      "source": [
        "# Fairness Attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAd8O8tYbekD"
      },
      "outputs": [],
      "source": [
        "def attack_balance(solution):\n",
        "  X_copy, s_copy = X.copy(), s.copy()\n",
        "  flipped_labels = solution.get_x()\n",
        "  i = 0\n",
        "  for idx in U_idx:\n",
        "    s_copy[idx] = flipped_labels[i]\n",
        "    i += 1\n",
        "\n",
        "  if cl_algo == 'FSC':\n",
        "    if name == 'MNIST_USPS':\n",
        "      metr_str = 'manhattan'\n",
        "    else:\n",
        "      metr_str = 'euclidean'\n",
        "    fair_clustering_algo = FairSpectral(n_clusters=n_clusters, num_neighbors=3, metric_str=metr_str, random_state=random_state)\n",
        "  if cl_algo =='SFD':\n",
        "    if name == 'DIGITS':      \n",
        "      fair_clustering_algo = ScalableFairletDecomposition(n_clusters=n_clusters, alpha=5, beta=1, random_state=random_state) \n",
        "    else:\n",
        "      fair_clustering_algo = ScalableFairletDecomposition(n_clusters=n_clusters, alpha=5, beta=2, random_state=random_state) \n",
        "  \n",
        "  fair_clustering_algo.fit(X_copy, s_copy)\n",
        "  labels_sfd = fair_clustering_algo.labels_\n",
        "\n",
        "  s_eval = []\n",
        "  X_eval = []\n",
        "  labels_sfd_eval = []\n",
        "  for idx in V_idx:\n",
        "    s_eval.append(s_copy[idx])\n",
        "    X_eval.append(X_copy[idx])\n",
        "    labels_sfd_eval.append(labels_sfd[idx])\n",
        "  s_eval = np.array(s_eval)\n",
        "  X_eval = np.array(X_eval)\n",
        "  labels_sfd_eval = np.array(labels_sfd_eval)\n",
        "\n",
        "  bal = balance(labels_sfd_eval, X_eval, s_eval)\n",
        "\n",
        "  return bal\n",
        "\n",
        "\n",
        "def attack_entropy(solution):\n",
        "  X_copy, s_copy = X.copy(), s.copy()\n",
        "  flipped_labels = solution.get_x()\n",
        "  i = 0\n",
        "  for idx in U_idx:\n",
        "    s_copy[idx] = flipped_labels[i]\n",
        "    i += 1\n",
        "\n",
        "  if cl_algo == 'FSC':\n",
        "    if name == 'MNIST_USPS':\n",
        "      metr_str = 'manhattan'\n",
        "    else:\n",
        "      metr_str = 'euclidean'\n",
        "    fair_clustering_algo = FairSpectral(n_clusters=n_clusters, num_neighbors=3, metric_str=metr_str, random_state=random_state)\n",
        "  if cl_algo =='SFD':\n",
        "    if name == 'DIGITS':      \n",
        "      fair_clustering_algo = ScalableFairletDecomposition(n_clusters=n_clusters, alpha=5, beta=1, random_state=random_state) \n",
        "    else:\n",
        "      fair_clustering_algo = ScalableFairletDecomposition(n_clusters=n_clusters, alpha=5, beta=2, random_state=random_state) \n",
        "  \n",
        "  fair_clustering_algo.fit(X_copy, s_copy)\n",
        "  labels_sfd = fair_clustering_algo.labels_\n",
        "\n",
        "  s_eval = []\n",
        "  X_eval = []\n",
        "  labels_sfd_eval = []\n",
        "  for idx in V_idx:\n",
        "    s_eval.append(s_copy[idx])\n",
        "    X_eval.append(X_copy[idx])\n",
        "    labels_sfd_eval.append(labels_sfd[idx])\n",
        "  s_eval = np.array(s_eval)\n",
        "  X_eval = np.array(X_eval)\n",
        "  labels_sfd_eval = np.array(labels_sfd_eval)\n",
        "\n",
        "  ent = entropy(labels_sfd_eval, s_eval)\n",
        "\n",
        "  return ent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6wxONfygXIh"
      },
      "outputs": [],
      "source": [
        "def process_solution(sol):\n",
        "  X_copy, s_copy, y_copy = X.copy(), s.copy(), y.copy()\n",
        "  flipped_labels = sol.get_x()\n",
        "  i = 0\n",
        "  for idx in U_idx:\n",
        "    s_copy[idx] = flipped_labels[i]\n",
        "    i += 1\n",
        "\n",
        "  if cl_algo == 'FSC':\n",
        "    if name == 'MNIST_USPS':\n",
        "      metr_str = 'manhattan'\n",
        "    else:\n",
        "      metr_str = 'euclidean'\n",
        "    fair_clustering_algo = FairSpectral(n_clusters=n_clusters, num_neighbors=3, metric_str=metr_str, random_state=random_state)\n",
        "  if cl_algo =='SFD':\n",
        "    if name == 'DIGITS':      \n",
        "      fair_clustering_algo = ScalableFairletDecomposition(n_clusters=n_clusters, alpha=5, beta=1, random_state=random_state)\n",
        "    else:\n",
        "      fair_clustering_algo = ScalableFairletDecomposition(n_clusters=n_clusters, alpha=5, beta=2, random_state=random_state) \n",
        "  \n",
        "  fair_clustering_algo.fit(X_copy, s_copy)\n",
        "  labels_sfd = fair_clustering_algo.labels_\n",
        "\n",
        "  s_eval = []\n",
        "  X_eval = []\n",
        "  labels_sfd_eval = []\n",
        "  y_eval = []\n",
        "  for idx in V_idx:\n",
        "    s_eval.append(s_copy[idx])\n",
        "    X_eval.append(X_copy[idx])\n",
        "    labels_sfd_eval.append(labels_sfd[idx])\n",
        "    y_eval.append(y_copy[idx])\n",
        "  s_eval = np.array(s_eval)\n",
        "  X_eval = np.array(X_eval)\n",
        "  labels_sfd_eval = np.array(labels_sfd_eval)\n",
        "  y_eval = np.array(y_eval)\n",
        "\n",
        "  bal = balance(labels_sfd_eval, X_eval, s_eval)\n",
        "  ent = entropy(labels_sfd_eval, s_eval)\n",
        "  accuracy = acc(y_eval, labels_sfd_eval)\n",
        "  nmi_score = nmi(y_eval, labels_sfd_eval)\n",
        "\n",
        "  return (bal, ent, accuracy, nmi_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vs6CcYUsMjLW"
      },
      "outputs": [],
      "source": [
        "def conduct_random_attack(size_sol):\n",
        "  X_copy, s_copy, y_copy = X.copy(), s.copy(), y.copy()\n",
        "  random.seed(None)\n",
        "  flipped_labels = [random.randint(0,1) for _ in range(size_sol)]\n",
        "  i = 0\n",
        "  for idx in U_idx:\n",
        "    s_copy[idx] = flipped_labels[i]\n",
        "    i += 1\n",
        "\n",
        "  if cl_algo == 'FSC':\n",
        "    if name == 'MNIST_USPS':\n",
        "      metr_str = 'manhattan'\n",
        "    else:\n",
        "      metr_str = 'euclidean'\n",
        "    fair_clustering_algo = FairSpectral(n_clusters=n_clusters, num_neighbors=3, metric_str=metr_str, random_state=random_state)\n",
        "  if cl_algo =='SFD':\n",
        "    if name == 'DIGITS':      \n",
        "      fair_clustering_algo = ScalableFairletDecomposition(n_clusters=n_clusters, alpha=5, beta=1, random_state=random_state) #5,2\n",
        "    else:\n",
        "      fair_clustering_algo = ScalableFairletDecomposition(n_clusters=n_clusters, alpha=5, beta=2, random_state=random_state) #5,2\n",
        "\n",
        "  fair_clustering_algo.fit(X_copy, s_copy)\n",
        "  labels_sfd = fair_clustering_algo.labels_\n",
        "\n",
        "  s_eval = []\n",
        "  X_eval = []\n",
        "  labels_sfd_eval = []\n",
        "  y_eval = []\n",
        "  for idx in V_idx:\n",
        "    s_eval.append(s_copy[idx])\n",
        "    X_eval.append(X_copy[idx])\n",
        "    labels_sfd_eval.append(labels_sfd[idx])\n",
        "    y_eval.append(y_copy[idx])\n",
        "  s_eval = np.array(s_eval)\n",
        "  X_eval = np.array(X_eval)\n",
        "  labels_sfd_eval = np.array(labels_sfd_eval)\n",
        "  y_eval = np.array(y_eval)\n",
        "\n",
        "  bal = balance(labels_sfd_eval, X_eval, s_eval)\n",
        "  ent = entropy(labels_sfd_eval, s_eval)\n",
        "  accuracy = acc(y_eval, labels_sfd_eval)\n",
        "  nmi_score = nmi(y_eval, labels_sfd_eval)\n",
        "\n",
        "  return (bal, ent, accuracy, nmi_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uel612jHeVs1"
      },
      "outputs": [],
      "source": [
        "n_clusters = len(np.unique(y))\n",
        "print(\"# of clusters -> \" + str(n_clusters))\n",
        "seeds = [150, 1, 4200, 424242, 1947, 355, 256, 7500, 99999, 18]\n",
        "n_trials = len(seeds)\n",
        "\n",
        "U_idx_full, V_idx_full = np.load('U_idx_' + name + '.npy').tolist(), np.load('V_idx_' + name + '.npy').tolist()\n",
        "\n",
        "pre_attack_res = {\n",
        "    0 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    1 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    2 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    3 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    4 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    5 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    6 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    7 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "}\n",
        "\n",
        "post_attack_res = {\n",
        "    0 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    1 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    2 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    3 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    4 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    5 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    6 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    7 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "}\n",
        "\n",
        "random_attack_res = {\n",
        "    0 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    1 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    2 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    3 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    4 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    5 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    6 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "    7 : {'BALANCE': [], 'ENTROPY': [], 'ACC': [], 'NMI': []},\n",
        "}\n",
        "\n",
        "for percent, j in enumerate([int(0.125*len(U_idx_full)), int(0.25*len(U_idx_full)), int(0.375*len(U_idx_full)), int(0.5*len(U_idx_full)), int(0.625*len(U_idx_full)), int(0.75*len(U_idx_full)), int(0.875*len(U_idx_full)), int(len(U_idx_full))]):\n",
        "  \n",
        "  U_idx = U_idx_full[:j]\n",
        "  V_idx = V_idx_full\n",
        "\n",
        "  for trial_idx in range(n_trials):\n",
        "    random_state = seeds[trial_idx]\n",
        "    \n",
        "    if cl_algo == 'FSC':\n",
        "      if name == 'MNIST_USPS':\n",
        "        metric_string = 'manhattan'\n",
        "      else:\n",
        "        metric_string = 'euclidean'\n",
        "      fair_algo = FairSpectral(n_clusters=n_clusters, num_neighbors=3, metric_str = metric_string, random_state=random_state)\n",
        "      fair_algo.fit(X, s)\n",
        "      labels = fair_algo.labels_\n",
        "    if cl_algo =='SFD':\n",
        "      if name == 'DIGITS':      \n",
        "        fair_algo = ScalableFairletDecomposition(n_clusters=n_clusters, alpha=5, beta=1, random_state=random_state) #5,2\n",
        "      else:\n",
        "        fair_algo = ScalableFairletDecomposition(n_clusters=n_clusters, alpha=5, beta=2, random_state=random_state) #5,2\n",
        "      fair_algo.fit(X, s)\n",
        "      labels = fair_algo.labels_\n",
        "    \n",
        "\n",
        "    s_test = []\n",
        "    X_test = []\n",
        "    labels_test = []\n",
        "    y_test = []\n",
        "    for idx in V_idx:\n",
        "      s_test.append(s[idx])\n",
        "      X_test.append(X[idx])\n",
        "      labels_test.append(labels[idx])\n",
        "      y_test.append(y[idx])\n",
        "    s_test = np.array(s_test)\n",
        "    X_test = np.array(X_test)\n",
        "    labels_test = np.array(labels_test)\n",
        "    y_test = np.array(y_test)\n",
        "\n",
        "    \n",
        "    pre_attack_res[percent]['BALANCE'].append(balance(labels_test, X_test, s_test))\n",
        "    pre_attack_res[percent]['ENTROPY'].append(entropy(labels_test, s_test))\n",
        "    pre_attack_res[percent]['ACC'].append(acc(y_test, labels_test))\n",
        "    pre_attack_res[percent]['NMI'].append(nmi(y_test, labels_test))\n",
        "    \n",
        "    dim_size = len(U_idx)\n",
        "    dim = Dimension(dim_size, [[0, 1]]*dim_size, [False]*dim_size)\n",
        "\n",
        "    if name == 'Office-31': #Only attack_balance\n",
        "      obj = Objective(attack_balance, dim)\n",
        "    elif name == 'MNIST_USPS' or name == 'DIGITS':\n",
        "      if cl_algo == 'SFD':\n",
        "        obj = Objective(attack_balance, dim)\n",
        "      elif cl_algo == 'FSC':\n",
        "        obj = Objective(attack_entropy, dim)\n",
        "    elif name == 'Yale': #Only attack_entropy\n",
        "      obj = Objective(attack_entropy, dim)\n",
        "    \n",
        "    solution = Opt.min(obj, Parameter(budget=10)) # 10 for FSC for MNIST_USPS and 50 for SFD for MNIST_USPS || 20 for FSC for Office-31 and 20 for SFD for Office-31 || 10 for FSC for Yale and 20 for SFD for Yale || 15 for FSC for DIGITS and 25 for SFD for DIGITS\n",
        "\n",
        "    \n",
        "    pa_bal, pa_ent, pa_acc, pa_nmi = process_solution(solution)\n",
        "    post_attack_res[percent]['BALANCE'].append(pa_bal)\n",
        "    post_attack_res[percent]['ENTROPY'].append(pa_ent)\n",
        "    post_attack_res[percent]['ACC'].append(pa_acc)\n",
        "    post_attack_res[percent]['NMI'].append(pa_nmi)\n",
        "\n",
        "    r_bal, r_ent, r_acc, r_nmi = conduct_random_attack(dim_size)\n",
        "    random_attack_res[percent]['BALANCE'].append(r_bal)\n",
        "    random_attack_res[percent]['ENTROPY'].append(r_ent)\n",
        "    random_attack_res[percent]['ACC'].append(r_acc)\n",
        "    random_attack_res[percent]['NMI'].append(r_nmi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJmvA3LPbLMX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}